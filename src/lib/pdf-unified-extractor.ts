/**
 * Unified PDF Extractor
 * 
 * Extracts both text and images from PDFs using a SINGLE pdfjs-dist document instance.
 * This eliminates redundant PDF scans and processes pages in parallel for maximum speed.
 */

import { initializeBrowserPolyfills } from '@/lib/polyfills/browser-apis'
import { applyGlobalPdfjsWorkerDisable } from '@/lib/pdfjs-config'

export interface ExtractedPDFContent {
  text: string
  images: Array<{
    image_data_b64: string
    page: number
    width: number
    height: number
    x?: number
    y?: number
  }>
}

/**
 * Extract both text and images from PDF using a single document load
 * Processes pages in parallel batches for 2-3x speedup
 */
export async function extractPDFTextAndImages(
  buffer: Buffer,
  filename: string
): Promise<ExtractedPDFContent> {
  // CRITICAL: Initialize browser API polyfills BEFORE any PDF parsing
  initializeBrowserPolyfills()
  // Belt-and-suspenders: apply global worker disable in case any downstream path bypasses config
  applyGlobalPdfjsWorkerDisable()

  if (process.env.NODE_ENV === 'development') {
    console.log(`üìÑ [UNIFIED PDF EXTRACTOR] Starting unified extraction from: ${filename}`)
  }

  const result: ExtractedPDFContent = {
    text: '',
    images: []
  }

  try {
    // Use serverless-compatible pdfjs configuration
    const { getPdfjsLib, SERVERLESS_PDF_OPTIONS } = await import('@/lib/pdfjs-config')
    const pdfjsLib = await getPdfjsLib()

    // Belt-and-suspenders: ensure worker is disabled right here too (prod-safe)
    // CRITICAL: Use empty string for workerSrc to prevent import errors in production
    if (pdfjsLib?.GlobalWorkerOptions) {
      pdfjsLib.GlobalWorkerOptions.workerSrc = ''
      ;(pdfjsLib.GlobalWorkerOptions as any).disableWorker = true
    } else {
      ;(pdfjsLib as any).GlobalWorkerOptions = { workerSrc: '', disableWorker: true }
    }
    if (typeof pdfjsLib?.setWorkerFetch === 'function') {
      try {
        pdfjsLib.setWorkerFetch(false)
      } catch (e) {
        // ignore
      }
    }

    // üöÄ OPTIMIZATION: Load PDF once, extract both text and images
    const loadingTask = pdfjsLib.getDocument({
      data: new Uint8Array(buffer),
      ...SERVERLESS_PDF_OPTIONS,
      disableWorker: true, // Force main-thread parsing to bypass workerSrc requirements
    })

    const pdfDocument = await loadingTask.promise

    if (process.env.NODE_ENV === 'development') {
      console.log(`  üìÑ [UNIFIED PDF EXTRACTOR] PDF loaded: ${pdfDocument.numPages} pages`)
    }

    // üöÄ OPTIMIZATION: Process pages in parallel batches
    const pageNumbers = Array.from({ length: pdfDocument.numPages }, (_, i) => i + 1)
    const batchSize = 5
    const batches: number[][] = []

    for (let i = 0; i < pageNumbers.length; i += batchSize) {
      batches.push(pageNumbers.slice(i, i + batchSize))
    }

    if (process.env.NODE_ENV === 'development') {
      console.log(`  üöÄ [UNIFIED PDF EXTRACTOR] Processing ${pdfDocument.numPages} pages in ${batches.length} parallel batches`)
    }

    const textParts: string[] = []
    const allImages: Array<{ image_data_b64: string; page: number; width: number; height: number }> = []

    // Process each batch in parallel
    for (const batch of batches) {
      const batchPromises = batch.map(async (pageNum) => {
        try {
          const page = await pdfDocument.getPage(pageNum)

          // Extract text and images from this page in parallel
          const [textContent, pageImages] = await Promise.all([
            // Extract text
            page.getTextContent().then((textContent: any) => {
              return textContent.items
                .map((item: any) => item.str)
                .join(' ')
            }),
            // Extract images
            extractImagesFromPage(page, pageNum, pdfDocument)
          ])

          return {
            pageNum,
            text: textContent,
            images: pageImages
          }
        } catch (pageError: any) {
          console.error(`  ‚ùå [UNIFIED PDF EXTRACTOR] Error processing page ${pageNum}:`, pageError.message)
          return {
            pageNum,
            text: '',
            images: []
          }
        }
      })

      // Wait for batch to complete
      const batchResults = await Promise.all(batchPromises)

      // Merge results
      for (const pageResult of batchResults) {
        if (pageResult.text) {
          textParts.push(pageResult.text)
        }
        allImages.push(...pageResult.images)
      }
    }

    // Combine text parts
    result.text = textParts.join('\n\n')

    // üéØ COORDINATION: Deduplicate images by hash
    const seenImageHashes = new Set<string>()
    for (const image of allImages) {
      // Create hash from base64 (first 100 chars)
      const hash = image.image_data_b64.substring(0, Math.min(100, image.image_data_b64.length))

      if (!seenImageHashes.has(hash)) {
        seenImageHashes.add(hash)
        result.images.push(image)
      } else if (process.env.NODE_ENV === 'development') {
        console.log(`  üîÑ [UNIFIED PDF EXTRACTOR] Skipped duplicate image on page ${image.page}`)
      }
    }

    if (process.env.NODE_ENV === 'development') {
      console.log(`  ‚úÖ [UNIFIED PDF EXTRACTOR] Extracted ${result.text.length} characters and ${result.images.length} images`)
    }

    return result
  } catch (error: any) {
    console.error(`  ‚ùå [UNIFIED PDF EXTRACTOR] Error extracting from ${filename}:`, error.message || error)
    // Return partial results if available
    return result
  }
}

/**
 * Extract images from a single PDF page
 */
async function extractImagesFromPage(
  page: any,
  pageNum: number,
  pdfDocument: any
): Promise<Array<{ image_data_b64: string; page: number; width: number; height: number }>> {
  const images: Array<{ image_data_b64: string; page: number; width: number; height: number }> = []

  try {
    // Get resources from page
    const resources = await page.getResources()

    if (!resources || !resources.obj) {
      return images
    }

    // Try to get XObject resources (where images are stored)
    const xObjects = resources.obj.get('XObject')

    if (xObjects && xObjects.get) {
      const xObjectKeys = xObjects.get('Keys') || []

      for (const key of xObjectKeys) {
        try {
          const xObject = xObjects.get(key)

          if (xObject && xObject.subtype && xObject.subtype.name === 'Image') {
            const width = xObject.width || 0
            const height = xObject.height || 0

            // Skip very small images (likely icons/decoration)
            if (width * height < 5000) {
              continue
            }

            // Get image data
            let imageData: Uint8Array | null = null

            if (xObject.data) {
              imageData = xObject.data
            } else if (xObject.getBytes) {
              imageData = await xObject.getBytes()
            }

            if (imageData && imageData.length > 0) {
              // Convert to base64
              const base64 = Buffer.from(imageData).toString('base64')

              images.push({
                image_data_b64: base64,
                page: pageNum,
                width,
                height
              })
            }
          }
        } catch (imgError) {
          // Skip images that can't be extracted
          if (process.env.NODE_ENV === 'development') {
            console.warn(`  ‚ö†Ô∏è [UNIFIED PDF EXTRACTOR] Failed to extract image ${key} from page ${pageNum}`)
          }
        }
      }
    }
  } catch (error) {
    if (process.env.NODE_ENV === 'development') {
      console.warn(`  ‚ö†Ô∏è [UNIFIED PDF EXTRACTOR] Error extracting images from page ${pageNum}:`, error)
    }
  }

  return images
}

