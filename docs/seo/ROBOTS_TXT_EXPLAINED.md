# Robots.txt Explained - Complete Guide

## ü§ñ What is robots.txt?

`robots.txt` is a text file that tells search engine crawlers (like Googlebot, Bingbot) which pages or sections of your website they can or cannot access. It's placed in the root directory of your website (e.g., `https://brainbattle.com/robots.txt`).

## üìã How It Works

### Basic Structure

```
User-agent: *
Allow: /
Disallow: /api/
Disallow: /admin/
Sitemap: https://brainbattle.com/sitemap.xml
```

### Components Explained

#### 1. User-agent
Specifies which crawler the rules apply to:
- `User-agent: *` = All crawlers
- `User-agent: Googlebot` = Only Google's crawler
- `User-agent: Bingbot` = Only Bing's crawler

#### 2. Allow
Tells crawlers which paths they CAN access:
- `Allow: /` = Allow everything
- `Allow: /features/` = Allow the features directory

#### 3. Disallow
Tells crawlers which paths they CANNOT access:
- `Disallow: /api/` = Don't crawl API routes
- `Disallow: /admin/` = Don't crawl admin pages
- `Disallow: /dashboard/` = Don't crawl user dashboards

#### 4. Sitemap
Points crawlers to your sitemap location:
- `Sitemap: https://brainbattle.com/sitemap.xml`

## ‚úÖ Is robots.txt Legal?

**YES, robots.txt is 100% legal and widely used.**

### Legal Status
- ‚úÖ **Standard Practice**: Used by millions of websites
- ‚úÖ **Recommended by Google**: Google officially supports and recommends it
- ‚úÖ **Industry Standard**: Part of the Robots Exclusion Protocol (REP)
- ‚úÖ **No Legal Issues**: It's a voluntary guideline, not a legal requirement

### Important Notes

1. **It's a Request, Not a Law**
   - robots.txt is a **courtesy**, not a security measure
   - Well-behaved crawlers respect it, but malicious bots may ignore it
   - **Don't rely on it for security** - use proper authentication instead

2. **It's Public**
   - Anyone can view your robots.txt by visiting `/robots.txt`
   - Don't put sensitive information in it
   - It can reveal your site structure (but that's usually fine)

3. **It's Voluntary**
   - Search engines choose to respect it
   - It's part of an informal agreement between site owners and crawlers
   - No legal enforcement, but industry-wide compliance

## üéØ Why Use robots.txt?

### Benefits

1. **Save Crawl Budget**
   - Prevent crawlers from wasting time on irrelevant pages
   - Focus crawling on important content
   - Faster indexing of valuable pages

2. **Protect Private Areas**
   - Keep admin panels out of search results
   - Hide API endpoints from indexing
   - Protect user dashboards

3. **Improve SEO**
   - Direct crawlers to important pages
   - Prevent duplicate content issues
   - Guide search engines to your sitemap

4. **Reduce Server Load**
   - Fewer unnecessary requests
   - Lower bandwidth usage
   - Better performance

## üìù Best Practices for Brain Battle

### What to Disallow

```txt
# API routes (no need to index)
Disallow: /api/

# Admin pages (private)
Disallow: /admin/

# User dashboards (private, require login)
Disallow: /dashboard/

# Private game rooms (session-specific)
Disallow: /room/
Disallow: /join-room/
Disallow: /create-room/

# Battle pages (session-specific, not useful in search)
Disallow: /singleplayer/battle/
Disallow: /room/*/battle/

# Internal testing pages
Disallow: /loading-test/
Disallow: /test/
```

### What to Allow

```txt
# Public pages (should be indexed)
Allow: /
Allow: /features/
Allow: /use-cases/
Allow: /alternatives/
Allow: /blog/
Allow: /pricing/
Allow: /about/

# Public API documentation (if you have it)
Allow: /docs/
```

### Complete Example for Brain Battle

```txt
User-agent: *
Allow: /
Disallow: /api/
Disallow: /admin/
Disallow: /dashboard/
Disallow: /room/
Disallow: /join-room/
Disallow: /create-room/
Disallow: /singleplayer/battle/
Disallow: /room/*/battle/
Disallow: /loading-test/
Disallow: /test/

# Sitemap location
Sitemap: https://brainbattle.com/sitemap.xml
```

## üö® Common Mistakes

### ‚ùå Don't Do This

```txt
# BAD: Blocking everything
User-agent: *
Disallow: /

# BAD: Blocking important pages
Disallow: /features/
Disallow: /blog/

# BAD: Using it for security
Disallow: /secret-admin-panel/  # Still accessible if someone knows the URL!
```

### ‚úÖ Do This Instead

```txt
# GOOD: Selective blocking
User-agent: *
Allow: /
Disallow: /api/
Disallow: /admin/

# GOOD: Use proper authentication for security
# robots.txt is NOT a security measure
```

## üîí Security Note

**CRITICAL**: robots.txt is NOT a security measure!

- ‚úÖ It's a **courtesy** to well-behaved crawlers
- ‚ùå It does NOT prevent access to pages
- ‚ùå Malicious bots can ignore it
- ‚ùå Anyone can view it and see what you're hiding

**For Security:**
- Use proper authentication (login required)
- Use server-side access control
- Use HTTPS
- Don't rely on robots.txt to hide sensitive data

## üìä How to Test Your robots.txt

### 1. Google Search Console
- Go to Google Search Console
- Use the robots.txt Tester tool
- Test specific URLs

### 2. Manual Testing
Visit: `https://brainbattle.com/robots.txt`

### 3. Online Validators
- robots.txt Validator tools
- Check syntax and common issues

## üõ†Ô∏è Implementation in Next.js

### Using Next.js App Router

Create `src/app/robots.ts`:

```typescript
import { MetadataRoute } from 'next'

export default function robots(): MetadataRoute.Robots {
  return {
    rules: {
      userAgent: '*',
      allow: '/',
      disallow: [
        '/api/',
        '/admin/',
        '/dashboard/',
        '/room/',
        '/join-room/',
        '/create-room/',
        '/singleplayer/battle/',
        '/loading-test/',
        '/test/',
      ],
    },
    sitemap: 'https://brainbattle.com/sitemap.xml',
  }
}
```

This automatically generates `/robots.txt` at build time.

## üìà Impact on SEO

### Positive Impact
- ‚úÖ Better crawl efficiency
- ‚úÖ Focus on important content
- ‚úÖ Faster indexing
- ‚úÖ Lower server load

### No Negative Impact
- ‚úÖ Doesn't hurt rankings
- ‚úÖ Doesn't prevent legitimate crawling
- ‚úÖ Standard practice (everyone uses it)

## üéØ Summary

**robots.txt is:**
- ‚úÖ Legal and standard practice
- ‚úÖ Recommended by Google
- ‚úÖ A courtesy to search engines
- ‚úÖ Useful for SEO optimization
- ‚úÖ Easy to implement in Next.js

**robots.txt is NOT:**
- ‚ùå A security measure
- ‚ùå Legally enforceable
- ‚ùå A guarantee (crawlers can ignore it)
- ‚ùå A replacement for proper authentication

**For Brain Battle:**
- Block API routes, admin pages, user dashboards
- Allow public pages (features, blog, pricing)
- Include sitemap reference
- Use Next.js `robots.ts` for easy implementation

---

**Last Updated:** January 2025

